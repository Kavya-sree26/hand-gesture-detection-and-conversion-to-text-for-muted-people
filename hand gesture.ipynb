{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a2856",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0433893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd57b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python tensorflow keras numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load dataset\n",
    "def load_data():\n",
    "    # Example: Generate synthetic data\n",
    "    X = np.random.rand(1000, 10)  # 1000 samples, 10 features\n",
    "    y = np.random.randint(0, 2, size=(1000, 1))  # Binary target\n",
    "    return X, y\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Build model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "    return model\n",
    "\n",
    "# Compile model\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "def train_model(model, X_train, y_train, epochs=10, batch_size=32):\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":   # ✅ fixed\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "    model = build_model(X_train.shape[1])\n",
    "    compile_model(model)\n",
    "    train_model(model, X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "gestures = {\n",
    "    0: \"Hello\",\n",
    "    1: \"Yes\", \n",
    "    2: \"No\",\n",
    "    3: \"Thank You\",\n",
    "    4: \"I Love You\"\n",
    "}\n",
    "\n",
    "def normalize_landmarks(landmarks):\n",
    "    \"\"\"Normalize landmarks relative to wrist position\"\"\"\n",
    "    landmarks = np.array(landmarks).reshape(-1, 2)\n",
    "    wrist = landmarks[0]\n",
    "    normalized = landmarks - wrist\n",
    "    if len(landmarks) > 12:\n",
    "        hand_size = np.linalg.norm(landmarks[12] - wrist)\n",
    "        if hand_size > 0:\n",
    "            normalized = normalized / hand_size\n",
    "    return normalized.flatten()\n",
    "\n",
    "def extract_features(landmarks):\n",
    "    \"\"\"Extract more robust features from landmarks\"\"\"\n",
    "    landmarks = np.array(landmarks).reshape(-1, 2)\n",
    "    features = []\n",
    "    normalized = normalize_landmarks(landmarks.flatten())\n",
    "    features.extend(normalized)\n",
    "\n",
    "    # Distances between key points\n",
    "    key_points = [0, 4, 8, 12, 16, 20]\n",
    "    for i in range(len(key_points)):\n",
    "        for j in range(i+1, len(key_points)):\n",
    "            if key_points[i] < len(landmarks) and key_points[j] < len(landmarks):\n",
    "                dist = np.linalg.norm(landmarks[key_points[i]] - landmarks[key_points[j]])\n",
    "                features.append(dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c29bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing to collect for [0] Hello ---\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "GESTURE_LABELS = {\n",
    "    0: \"Hello\",\n",
    "    1: \"Yes\",\n",
    "    2: \"No\",\n",
    "    3: \"Thank You\",\n",
    "    4: \"I Love You\",\n",
    "    5: \"Stop\",\n",
    "    6: \"Help\",\n",
    "    7: \"Wait\",\n",
    "    8: \"Bye\",\n",
    "    9: \"Good Morning\",\n",
    "    10: \"Good Night\",\n",
    "    11: \"Sorry\",\n",
    "    12: \"OK\",\n",
    "    13: \"Peace\",\n",
    "    14: \"Rock\",\n",
    "    15: \"Thumbs Up\",\n",
    "    16: \"Thumbs Down\",\n",
    "    17: \"Call Me\",\n",
    "    18: \"Hungry\",\n",
    "    19: \"Thirsty\",\n",
    "    20: \"Pain\",\n",
    "    21: \"Emergency\",\n",
    "    22: \"Washroom\",\n",
    "    23: \"Come Here\",\n",
    "    24: \"Go Away\",\n",
    "    25: \"Love\",\n",
    "    26: \"Angry\",\n",
    "    27: \"Confused\",\n",
    "    28: \"Relax\",\n",
    "    29: \"Super\"\n",
    "}\n",
    "\n",
    "SAMPLES_PER_LABEL = 40      # how many samples to collect per gesture\n",
    "COUNTDOWN_SECS = 3         # countdown before capturing each batch\n",
    "CAPTURE_INTERVAL = 0.4     # seconds between each sample capture\n",
    "SAVE_IMAGES = True         # save camera images of each sample (helpful for debugging)\n",
    "OUTPUT_DIR = \"gesture_dataset\"\n",
    "IMAGES_DIR = os.path.join(OUTPUT_DIR, \"images\")\n",
    "LANDMARKS_FILE = os.path.join(OUTPUT_DIR, \"landmarks.npz\")\n",
    "META_CSV = os.path.join(OUTPUT_DIR, \"metadata.csv\")\n",
    "# ============================\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "if SAVE_IMAGES:\n",
    "    os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def normalize_landmarks_flat(landmarks_flat):\n",
    "    \"\"\"\n",
    "    landmarks_flat: list or array [x0,y0,x1,y1,...]\n",
    "    returns normalized flattened vector: coordinates shifted by wrist and scaled by hand size\n",
    "    \"\"\"\n",
    "    arr = np.array(landmarks_flat).reshape(-1, 2)\n",
    "    wrist = arr[0].copy()\n",
    "    arr = arr - wrist\n",
    "    if arr.shape[0] > 12:\n",
    "        hand_size = np.linalg.norm(arr[12])  # after subtracting wrist, index 12 is distance vector\n",
    "        if hand_size > 1e-6:\n",
    "            arr = arr / hand_size\n",
    "    return arr.flatten()\n",
    "\n",
    "def landmarks_to_flat(landmarks):\n",
    "    return [lm.x for lm in landmarks] + [lm.y for lm in landmarks]  # first all x then all y? (we'll keep x,y pair order)\n",
    "    # NOTE: above line actually concatenates xs then ys — we'll prefer x,y pairs:\n",
    "def landmarks_to_flat_xy(landmarks):\n",
    "    flat = []\n",
    "    for lm in landmarks:\n",
    "        flat.extend([lm.x, lm.y])\n",
    "    return flat\n",
    "\n",
    "def draw_overlay(frame, title, subtitle, progress_text):\n",
    "    h, w = frame.shape[:2]\n",
    "    # translucent background\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (0, 0), (w, 75), (0, 0, 0), -1)\n",
    "    alpha = 0.5\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "    cv2.putText(frame, title, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, subtitle, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 1)\n",
    "    if progress_text:\n",
    "        cv2.putText(frame, progress_text, (w - 10 - 400, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Could not open camera. Check your webcam.\")\n",
    "        return\n",
    "\n",
    "    all_landmarks = []   # list of normalized flattened vectors\n",
    "    all_labels = []      # integer labels\n",
    "    metadata = []        # rows: [label, label_name, timestamp, image_path (optional)]\n",
    "\n",
    "    # For quick progress display\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    with mp_hands.Hands(\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=0.6,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as hands:\n",
    "\n",
    "        for label_id in sorted(GESTURE_LABELS.keys()):\n",
    "            label_name = GESTURE_LABELS[label_id]\n",
    "            print(f\"\\n--- Preparing to collect for [{label_id}] {label_name} ---\")\n",
    "            # Wait for user to be ready\n",
    "            ready = False\n",
    "            while not ready:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Error reading frame.\")\n",
    "                    return\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                draw_overlay(frame,\n",
    "                             f\"Prepare for: {label_id} - {label_name}\",\n",
    "                             f\"Hold the gesture. Countdown starts when you press SPACE. Press 's' to skip label.\",\n",
    "                             f\"Collected: {counts[label_id]}/{SAMPLES_PER_LABEL}\")\n",
    "                cv2.imshow(\"Capture Gestures\", frame)\n",
    "                k = cv2.waitKey(1) & 0xFF\n",
    "                if k == ord(' '):   # SPACE starts countdown\n",
    "                    ready = True\n",
    "                elif k == ord('s'): # skip this label\n",
    "                    print(f\"Skipped label {label_id}\")\n",
    "                    break\n",
    "                elif k == ord('q'):\n",
    "                    print(\"Quitting early by user.\")\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    # Save whatever we have\n",
    "                    save_dataset(all_landmarks, all_labels, metadata)\n",
    "                    return\n",
    "\n",
    "            if not ready:\n",
    "                continue\n",
    "\n",
    "            # countdown\n",
    "            for c in range(COUNTDOWN_SECS, 0, -1):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                draw_overlay(frame,\n",
    "                             f\"Get ready: {label_name}\",\n",
    "                             f\"Capturing in... {c}\",\n",
    "                             f\"Collected: {counts[label_id]}/{SAMPLES_PER_LABEL}\")\n",
    "                cv2.imshow(\"Capture Gestures\", frame)\n",
    "                cv2.waitKey(1000)\n",
    "\n",
    "            print(f\"Start capturing {SAMPLES_PER_LABEL} samples for '{label_name}'\")\n",
    "\n",
    "            # capture loop\n",
    "            captured = 0\n",
    "            last_capture_time = 0\n",
    "            while captured < SAMPLES_PER_LABEL:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Frame read error, trying again...\")\n",
    "                    continue\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = hands.process(rgb)\n",
    "\n",
    "                # draw landmarks if found\n",
    "                if results and results.multi_hand_landmarks:\n",
    "                    for hl in results.multi_hand_landmarks:\n",
    "                        mp_drawing.draw_landmarks(frame, hl, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                now = time.time()\n",
    "                if now - last_capture_time >= CAPTURE_INTERVAL:\n",
    "                    # if a hand is detected, capture; otherwise wait\n",
    "                    if results and results.multi_hand_landmarks:\n",
    "                        hand_landmarks = results.multi_hand_landmarks[0].landmark\n",
    "                        flat = landmarks_to_flat_xy(hand_landmarks)\n",
    "                        norm = normalize_landmarks_flat(flat)\n",
    "                        all_landmarks.append(norm)\n",
    "                        all_labels.append(label_id)\n",
    "                        ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "                        img_path = \"\"\n",
    "                        if SAVE_IMAGES:\n",
    "                            img_name = f\"label_{label_id}_{label_name.replace(' ', '_')}_{counts[label_id]:03d}_{ts}.jpg\"\n",
    "                            img_path = os.path.join(IMAGES_DIR, img_name)\n",
    "                            cv2.imwrite(img_path, frame)\n",
    "                        metadata.append([label_id, label_name, time.time(), img_path])\n",
    "                        captured += 1\n",
    "                        counts[label_id] += 1\n",
    "                        last_capture_time = now\n",
    "                        print(f\"Captured {captured}/{SAMPLES_PER_LABEL} for {label_name}\")\n",
    "\n",
    "                draw_overlay(frame,\n",
    "                             f\"Collecting: {label_id} - {label_name}\",\n",
    "                             f\"Samples: {captured}/{SAMPLES_PER_LABEL}  (Press 'q' to stop)\",\n",
    "                             f\"Total saved so far: {sum(counts.values())}\")\n",
    "                cv2.imshow(\"Capture Gestures\", frame)\n",
    "                k = cv2.waitKey(1) & 0xFF\n",
    "                if k == ord('q'):\n",
    "                    print(\"User requested early quit.\")\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    save_dataset(all_landmarks, all_labels, metadata)\n",
    "                    return\n",
    "\n",
    "            print(f\"Completed label {label_id} ({label_name}). Moving to next.\")\n",
    "\n",
    "    # finished all labels\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    save_dataset(all_landmarks, all_labels, metadata)\n",
    "    print(\"All done. Dataset saved.\")\n",
    "\n",
    "def save_dataset(landmarks_list, labels_list, metadata_rows):\n",
    "    if len(landmarks_list) == 0:\n",
    "        print(\"No samples to save.\")\n",
    "        return\n",
    "\n",
    "    # pad to same length if needed and stack\n",
    "    max_len = max(len(x) for x in landmarks_list)\n",
    "    X = np.array([np.pad(x, (0, max_len - len(x)), 'constant') for x in landmarks_list])\n",
    "    y = np.array(labels_list)\n",
    "\n",
    "    # save numpy compressed\n",
    "    np.savez_compressed(LANDMARKS_FILE, X=X, y=y)\n",
    "    print(f\"Saved landmarks -> {LANDMARKS_FILE}  (samples: {len(y)})\")\n",
    "\n",
    "    # save metadata csv\n",
    "    header = [\"label_id\", \"label_name\", \"timestamp\", \"image_path\"]\n",
    "    with open(META_CSV, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for row in metadata_rows:\n",
    "            writer.writerow(row)\n",
    "    print(f\"Saved metadata -> {META_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
