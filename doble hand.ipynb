{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02605a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gesture Recognition Started (Hold 2 sec for speech)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# -------------------- MEDIAPIPE SETUP --------------------\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# -------------------- AUDIO SETUP --------------------\n",
    "pygame.mixer.init()\n",
    "\n",
    "is_speaking = False\n",
    "gesture_hold_time = 2.0\n",
    "last_spoken_gesture = \"\"\n",
    "\n",
    "# -------------------- SPEAK FUNCTION --------------------\n",
    "def speak(text):\n",
    "    global is_speaking\n",
    "\n",
    "    def run():\n",
    "        global is_speaking\n",
    "        try:\n",
    "            is_speaking = True\n",
    "\n",
    "            temp_file = os.path.join(tempfile.gettempdir(), \"gesture_speech.mp3\")\n",
    "            gTTS(text=text, lang=\"en\").save(temp_file)\n",
    "\n",
    "            pygame.mixer.music.load(temp_file)\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "            while pygame.mixer.music.get_busy():\n",
    "                time.sleep(0.1)\n",
    "\n",
    "            pygame.mixer.music.unload()\n",
    "            os.remove(temp_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Speech Error:\", e)\n",
    "\n",
    "        is_speaking = False\n",
    "\n",
    "    if not is_speaking:\n",
    "        threading.Thread(target=run, daemon=True).start()\n",
    "\n",
    "# -------------------- FINGER STATES --------------------\n",
    "def get_finger_states(hand_landmarks, handedness):\n",
    "    finger_states = []\n",
    "\n",
    "    finger_tips = [8, 12, 16, 20]\n",
    "    finger_pips = [6, 10, 14, 18]\n",
    "\n",
    "    for tip, pip in zip(finger_tips, finger_pips):\n",
    "        finger_states.append(1 if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[pip].y else 0)\n",
    "\n",
    "    thumb_tip = hand_landmarks.landmark[4]\n",
    "    thumb_ip = hand_landmarks.landmark[3]\n",
    "\n",
    "    if handedness == \"Right\":\n",
    "        thumb_up = thumb_tip.x < thumb_ip.x\n",
    "    else:\n",
    "        thumb_up = thumb_tip.x > thumb_ip.x\n",
    "\n",
    "    finger_states.insert(0, 1 if thumb_up else 0)\n",
    "    return finger_states\n",
    "\n",
    "# -------------------- GESTURE DICTIONARY --------------------\n",
    "gesture_dict = {\n",
    "\n",
    "    # -------- TWO HAND GESTURES (10 VALUES) --------\n",
    "\n",
    "    (1,1,1,1,1, 0,1,0,0,0): {\n",
    "        \"name\": \"Good Morning\",\n",
    "        \"sentence\": \"Good morning\"\n",
    "    },\n",
    "\n",
    "    (0,1,1,0,0, 0,1,0,0,0): {\n",
    "        \"name\": \"How Are You\",\n",
    "        \"sentence\": \"How are you\"\n",
    "    },\n",
    "\n",
    "    (1,0,0,0,0, 1,0,0,1,0): {\n",
    "        \"name\": \"I Am Fine\",\n",
    "        \"sentence\": \"I am fine\"\n",
    "    },\n",
    "\n",
    "    (0,0,0,1,1, 1,1,1,1,1): {\n",
    "        \"name\": \"Thank You\",\n",
    "        \"sentence\": \"Thank you very much\"\n",
    "    },\n",
    "\n",
    "    (1,0,0,0,0, 1,1,1,0,1): {\n",
    "        \"name\": \"Hungry\",\n",
    "        \"sentence\": \"I am hungry\"\n",
    "    },\n",
    "\n",
    "    (0,0,1,1,1, 0,1,1,1,0): {\n",
    "        \"name\": \"Stop\",\n",
    "        \"sentence\": \"Stop please\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------- MAIN LOOP --------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "current_gesture = None\n",
    "gesture_start_time = None\n",
    "\n",
    "print(\"\\nGesture Recognition Started (Hold 2 sec for speech)\\n\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb)\n",
    "\n",
    "    current_time = time.time()\n",
    "    fingers_combined = []\n",
    "    gesture_info = None\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            handedness = results.multi_handedness[idx].classification[0].label\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS\n",
    "            )\n",
    "\n",
    "            fingers = get_finger_states(hand_landmarks, handedness)\n",
    "            fingers_combined.extend(fingers)\n",
    "\n",
    "        if len(fingers_combined) == 10:\n",
    "            gesture_info = gesture_dict.get(tuple(fingers_combined))\n",
    "\n",
    "        if gesture_info:\n",
    "            name = gesture_info[\"name\"]\n",
    "            sentence = gesture_info[\"sentence\"]\n",
    "\n",
    "            cv2.putText(frame, f\"Gesture: {name}\", (10, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "            if current_gesture != name:\n",
    "                current_gesture = name\n",
    "                gesture_start_time = current_time\n",
    "                last_spoken_gesture = \"\"\n",
    "\n",
    "            if current_time - gesture_start_time >= gesture_hold_time:\n",
    "                if last_spoken_gesture != name and not is_speaking:\n",
    "                    speak(sentence)\n",
    "                    last_spoken_gesture = name\n",
    "    else:\n",
    "        current_gesture = None\n",
    "        gesture_start_time = None\n",
    "        cv2.putText(frame, \"No Hand Detected\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Hand Gesture â†’ Speech\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.mixer.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
